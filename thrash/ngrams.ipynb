{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngram Tutorial \n",
    "N-gram is a contiguous sequence of n items from a given sequence of text or speech. The items can be phonemes, syllables, letters, words or base pairs according to the application. The n-grams typically are collected from a text or speech corpus.\n",
    "\n",
    "An n-gram of size 1 is referred to as a \"unigram\"; size 2 is a \"bigram\" (or, less commonly, a \"digram\"); size 3 is a \"trigram\". Larger sizes are sometimes referred to by the value of n, e.g., \"four-gram\", \"five-gram\", and so on. [Wikipedia](https://en.wikipedia.org/wiki/N-gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram extraction for feature space construction\n",
    "Below is a very short introduction to ngrams explaining their extraction in examples as well as in code.\n",
    "Source: This [blog post](https://cmry.github.io/notes/ngrams) by Chris Emmery\n",
    "\n",
    "The extraction of n-grams is a commonly used as a so-called bag-of-words method used in [Natural Language Processing (NLP)](https://en.wikipedia.org/wiki/Natural_language_processing) to represent a collection of documents. In a very basic example we want to either distinguish or relate sentence **A**, **B**, and **C** which are the following:\n",
    "\n",
    "```python\n",
    "A = 'text about stuff'\n",
    "B = 'stuff about text'\n",
    "C = 'text about n-grams'```\n",
    "\n",
    "The **n** in n-grams typically refers to a scope. One can look at it as going over the sentence with a **window of some size**. So with a 1-gram (referred to as a unigram) we partition the text in chunks of size one. So sentence A would give us <span style=\"color:blue\">text</span>, <span style=\"color:blue\">about</span>, and <span style=\"color:blue\">stuff</span>. If we would put this into a matrix of gram * sentence, we would get the following for the three sentences:\n",
    "\n",
    " | sentence **A** | sentence **B** | sentence **C**\n",
    ":---: | :----: | :---: | :---:\n",
    "text | 1 | 1 | 1\n",
    "about | 1 | 1 | 1\n",
    "stuff | 1 | 1 | 0 \n",
    "n-grams | 0 | 0 | 1\n",
    "\n",
    "*Note: The gram <span style=\"color:blue\">text</span> occurs in text **A** one time, while <span style=\"color:blue\">n-grams</span> does not occur in **A***\n",
    " \n",
    "Looking at the matrix, one can quickly see that despite the order of words, sentence **A** and **B** look the same. If we take their vector they can be observed to be identical:\n",
    "\n",
    "$$\\vec{A}=[1,1,1,0],\\vec{B}=[1,1,1,0]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is is what it means to have a *bag-of-words*. Words are thrown into a bag, scrambled in any order and counted. **Order does not matter** to the model. So how can we incorporate some structure into it? Taking word bi-grams, where <span style=\"color:blue\">n = 2</span> would probably already help our case. Consider:\n",
    "\n",
    " | sentence **A** | sentence **B** | sentence **C**\n",
    ":---: | :----: | :---: | :---:\n",
    "text about | 1 | 0 | 1\n",
    "about stuff | 1 | 0 | 0\n",
    "stuff about | 0 | 1 | 0 \n",
    "about text | 0 | 1 | 0\n",
    "about n-grams | 0 | 0 | 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the vectors of **A**, **B** and **C** are all unique. Moreover, it can actually be inferred that **A** and **C** have some relation, but they both don’t relate to **B**. Done right? Well, not quite. What if we introduce a fourth sentence:\n",
    "\n",
    "```python\n",
    "D = 'n-grams are handy'```\n",
    "\n",
    "We construct the matrix again:\n",
    "\n",
    " | sentence **A** | sentence **B** | sentence **C** | sentence **D**\n",
    ":---: | :----: | :---: | :---: | :---:\n",
    "text about | 1 | 0 | 1 | 0\n",
    "about stuff | 1 | 0 | 0 | 0\n",
    "stuff about | 0 | 1 | 0 | 0\n",
    "about text | 0 | 1 | 0 | 0\n",
    "about n-grams | 0 | 0 | 1 | 0\n",
    "n-grams are | 0 | 0 | 0 | 1\n",
    "are handy | 0 | 0 | 0 | 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could say that **D** relates to **C**, but it doesn’t show with this method. With our uni-gram method it might, but we run into trouble with **A** and **B** being identical again. Instead of words, we might draw more information from the character combinations instead. Let’s take <span style=\"color:blue\">tri-grams</span> (3-grams), and see:\n",
    "\n",
    " | sentence **A** | sentence **B** | sentence **C** | sentence **D**\n",
    ":---: | :----: | :---: | :---: | :---:\n",
    "tex | 1 | 1 | 1 | 0\n",
    "ext | 1 | 1 | 1 | 0\n",
    "xta | 1 | 0 | 1 | 0\n",
    "tab | 1 | 0 | 1 | 0\n",
    "abo | 1 | 1 | 1 | 0\n",
    "bou | 1 | 1 | 1 | 0\n",
    "out | 1 | 1 | 1 | 0\n",
    "tst | 1 | 0 | 0 | 0\n",
    "uts | 1 | 0 | 0 | 0\n",
    "stu | 1 | 1 | 0 | 0\n",
    "tuf | 1 | 1 | 0 | 0\n",
    "uff | 1 | 1 | 0 | 0\n",
    "ffa | 0 | 1 | 0 | 0\n",
    "fab | 0 | 1 | 0 | 0\n",
    "utt | 0 | 1 | 0 | 0\n",
    "tte | 0 | 1 | 0 | 0\n",
    "utn | 0 | 0 | 1 | 0\n",
    "tn- | 0 | 0 | 1 | 0\n",
    "n-g | 0 | 0 | 1 | 1\n",
    "-gr | 0 | 0 | 1 | 1\n",
    "gra | 0 | 0 | 1 | 1\n",
    "ram | 0 | 0 | 1 | 1\n",
    "ams | 0 | 0 | 1 | 1\n",
    "msa | 0 | 0 | 0 | 1\n",
    "sar | 0 | 0 | 0 | 1\n",
    "are | 0 | 0 | 0 | 1\n",
    "reh | 0 | 0 | 0 | 1\n",
    "eha | 0 | 0 | 0 | 1\n",
    "han | 0 | 0 | 0 | 1\n",
    "and | 0 | 0 | 0 | 1\n",
    "ndy | 0 | 0 | 0 | 1\n",
    "\n",
    "*Note: **Spaces** were removed to avoid the matrix blowing up even more.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the overlap between the different sentences is more evident, but with an explosion of the matrix as a result. As can be observed, **different grams vary in usefulness**; for sentence relatedness, tri-grams might be more useful - however, they obscure the actual word usage. The latter can be seen as problematic when the task is to **distinguish certain topics**. For example, if we want to measure the relatedness of sentences A through D to NLP, it’s more effective to represent <span style=\"color:blue\">n-grams</span> as a full chunk rather than <span style=\"color:blue\">['n-g', '-gr', 'gra', etc.]</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **explosion** of the amount of grams per sentence makes it harder for algorithms to uncover relations; as it would have to rely on a combination of the grams for information, rather than their single occurrences. Another caveat is the **sparseness of the vectors**: the rarer the occurrences, the more zeroes are present in sentence vectors, the less information a vector provides per bit. In the above example this is already pretty evident from a very small example, imagine a corpus of a million documents. How one would go about programming this in an effective manner is the topic of this particular tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 - a Little Naive, But Dependency Free\n",
    "First we will consider implementing a simple sliding window of n to extract the grams from a sentence. Such that, given sentence A again, we get the grams as we saw in the previous example. So something like:\n",
    "\n",
    "```python\n",
    "In [1]: find_ngrams('text about stuff', n=2)\n",
    "Out[1]: ['text about', 'about stuff']```\n",
    "\n",
    "Or even:\n",
    "\n",
    "```python\n",
    "In [1]: find_ngrams('text about stuff', n_list=[1, 2])\n",
    "Out[1]: ['text', 'about', 'stuff', 'text about', 'about stuff']```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An effective algorithm as proven by this [post](https://stackoverflow.com/questions/21883108/fast-optimize-n-gram-implementations-in-python/21988533#21988533) is to abuse zip and slicing in python. So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_ngrams(sentence, n):\n",
    "    \"\"\"Magic n-gram function.\"\"\"\n",
    "    inp = sentence.split()\n",
    "    return zip(*[inp[i:] for i in range(n)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above method will give us a list of tuples of size n, extracted in a sliding window. If we alter the function slightly, we will be able to achieve the desired result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ngrams(sentence, n_list):\n",
    "    \"\"\"Magic n-gram function.\"\"\"\n",
    "    inp, grams = sentence.split(), []\n",
    "    for n in n_list:\n",
    "        grams += [' '.join(x) for x in zip(*[inp[i:] for i in range(n)])]\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should be able to turn sentences into vectors representing the gram occurrences in a sentence. So that <span style=\"color:blue\">the the a a thing</span> would at least yield <span style=\"color:blue\">[2, 2, 1]</span>. This entails incorporating the search function into a neat class that can fit the known grams and make sure their index in the vector is the same for all sentences. A very compact class doing exactly this would look something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ngrams:\n",
    "\n",
    "    def __init__(self, n_list):\n",
    "        self.n_list = n_list\n",
    "        self.indices = {}\n",
    "\n",
    "    def fit(self, sentence):\n",
    "        \"\"\"Magic n-gram function fits to vector indices.\"\"\"\n",
    "        i, inp = len(self.indices)-1, sentence.split()\n",
    "        for n in self.n_list:\n",
    "            for x in zip(*[inp[i:] for i in range(n)]):\n",
    "                if self.indices.get(x) == None:\n",
    "                    i += 1\n",
    "                    self.indices.update({x: i})\n",
    "\n",
    "    def transform(self, sentence):\n",
    "        \"\"\"Given a sentence, convert to a gram vector.\"\"\"\n",
    "        v, inp = [0] * len(self.indices), sentence.split()\n",
    "        for n in self.n_list:\n",
    "            for x in zip(*[inp[i:] for i in range(n)]):\n",
    "                if self.indices.get(x) != None:\n",
    "                    v[self.indices[x]] += 1\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we call the <span style=\"color:blue\">fit</span> method to extract the n-grams and index them to <span style=\"color:blue\">self.indices</span>. Next time the function sees a sentences, it will know where in a vector to place the frequencies, as well as which words are not part of that vector. This can be seen in the <span style=\"color:blue\">transform</span> part where it begins with an empty vector of size <span style=\"color:blue\">self.indices</span> and starts filling in the frequencies. A major drawback of this approach is that the corpus needs to be iterated over twice; once for extracting all possible nn-grams, and once this is known, another passover to convert all sentences to vectors. Still, this works, proven by the example below. Please pay close attention to the <span style=\"color:blue\">dict.get == None</span> or <span style=\"color:blue\">!= None</span> parts. Given that we have a <span style=\"color:blue\">{gram: index}</span> dictionary, a simple <span style=\"color:blue\">if self.indices.get</span> would not pass a <span style=\"color:blue\">0</span> index, since Python sees that as <span style=\"color:blue\">False</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ng = Ngrams(n_list=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ng.fit('text about stuff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng.transform('text about stuff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ng.fit('n-grams are handy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng.transform('text about n-grams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('about',): 1,\n",
       " ('about', 'stuff'): 4,\n",
       " ('are',): 6,\n",
       " ('are', 'handy'): 9,\n",
       " ('handy',): 7,\n",
       " ('n-grams',): 5,\n",
       " ('n-grams', 'are'): 8,\n",
       " ('stuff',): 2,\n",
       " ('text',): 0,\n",
       " ('text', 'about'): 3}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng.indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To counter the complexity issue from passing over whatever copora twice, it would be a lot better if a vector or even a matrix could be constructed from the frequencies that we can already extract at the <span style=\"color:blue\">fit</span> step. For this, a feature hasher such as the one implemented in sklearn, or the dict vectorizer would be of great use, as we can see here: [Method 2 - Sentences to Sparse Vectors](https://cmry.github.io/notes/ngrams)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
