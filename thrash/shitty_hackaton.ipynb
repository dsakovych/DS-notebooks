{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from stop_words import get_stop_words\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "import re, nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer        \n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA = os.path.join(os.getcwd(),'data.xlsx')\n",
    "\n",
    "df = pd.read_excel(DATA)\n",
    "df = shuffle(df)\n",
    "df = df[df['Краткое описание'].notnull()]\n",
    "\n",
    "category_encoding = dict(zip(list(df['Категория'].unique()), [0,1,2,3]))\n",
    "\n",
    "df['label'] = df['Категория']#.apply(lambda x: category_encoding[x])\n",
    "df['desc'] = df['Краткое описание']\n",
    "df = df.drop(labels=['Краткое описание', 'Категория'], axis=1)\n",
    "\n",
    "punctuation += '№'\n",
    "\n",
    "stopwords = get_stop_words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(inp_str):\n",
    "    inp_str = inp_str.lower()\n",
    "\n",
    "    # replace redundant_signs\n",
    "    for item in punctuation:\n",
    "        inp_str = inp_str.replace(item, ' ')\n",
    "\n",
    "    # replace digits\n",
    "    inp_str = re.sub('\\d', ' ', inp_str)\n",
    "    inp_str = ' '.join(list(filter(None, inp_str.split(' '))))\n",
    "    return inp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_data = df['desc'].apply(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('для', 4433),\n",
       " ('доступа', 4127),\n",
       " ('действия', 3983),\n",
       " ('срок', 3971),\n",
       " ('сотрудника', 3967),\n",
       " ('таб', 3525),\n",
       " ('в', 2534),\n",
       " ('пароль', 2471),\n",
       " ('sap', 2435),\n",
       " ('пароля', 1391),\n",
       " ('к', 1379),\n",
       " ('hr', 1250),\n",
       " ('доступы', 1222),\n",
       " ('закрыты', 1077),\n",
       " ('с', 910),\n",
       " ('обнулить', 907),\n",
       " ('работы', 861),\n",
       " ('обнуление', 836),\n",
       " ('увольнение', 810),\n",
       " ('jrm', 645),\n",
       " ('просьба', 578),\n",
       " ('ир', 569),\n",
       " ('прошу', 454),\n",
       " ('доступ', 383),\n",
       " ('володимирович', 369)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = text_data.str.lower().str.cat(sep=' ')\n",
    "words = nltk.word_tokenize(txt)\n",
    "word_dist = nltk.FreqDist(words)\n",
    "most_common_words = word_dist.most_common(25)\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "def tokenize(text):\n",
    "    text = re.sub(\"[а-я]\", \" \", text)\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    stemmer = SnowballStemmer(\"russian\")\n",
    "    stems = [stemmer.stem(word) for word in word_list]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokenize, stop_words = most_common_words)\n",
    "data_features = vectorizer.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        df['desc'], \n",
    "        df['label'],\n",
    "        test_size=0.2, \n",
    "        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('vectorizer', vectorizer), \n",
    "                     ('classifier', LogisticRegression())])\n",
    "model = pipeline.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "                Обнуление пароля       0.90      0.97      0.93      1013\n",
      "             Отзыв доступов к ИС       0.97      0.96      0.96      1255\n",
      "  Предоставление доступов в сеть       0.78      0.29      0.42        24\n",
      "Сетевые папки - Файловые ресурсы       1.00      0.09      0.16        57\n",
      "\n",
      "                     avg / total       0.94      0.93      0.92      2349\n",
      "\n",
      "accuracy: 0.934014474244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# save the classifier\n",
    "with open('my_dumped_classifier.pkl', 'wb') as fid:\n",
    "    pickle.dump(model, fid)\n",
    "    \n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('my_dumped_classifier.pkl', 'rb') as model_bin:\n",
    "    model = pickle.load(model_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Отзыв доступов к ИС'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = ['help me. please!']\n",
    "test_sample1 = ['Срок действия доступа для сотрудника Бичков Андрій Валерійович  (таб.№ 50137450']\n",
    "\n",
    "model.predict(test_sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
